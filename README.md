# ğŸ¯ Zoom Sidekick MVP

![Python](https://img.shields.io/badge/Python-3.11-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.99-green)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT-blueviolet)
![Docker](https://img.shields.io/badge/Docker-Ready-blue)
![Status](https://img.shields.io/badge/Status-MVP-orange)
![License](https://img.shields.io/badge/License-MIT-yellow)


## ğŸš€ DescriÃ§Ã£o do Projeto

O **Zoom Sidekick MVP** Ã© uma soluÃ§Ã£o de **entrevista automatizada com IA**, capaz de:

* ğŸ™ï¸ Capturar Ã¡udio do usuÃ¡rio em tempo real
* ğŸ“ Transcrever respostas (STT - Whisper)
* ğŸ§  Resumir respostas (GPT - OpenAI)
* ğŸ”Š Gerar Ã¡udio da prÃ³xima pergunta (TTS - gTTS)
* ğŸ¤– Conduzir entrevistas completas de forma automatizada

> MVP funcional, com **backend modular** e **frontend responsivo**, pronto para integraÃ§Ã£o com Zoom ou Google Meet.


## ğŸ—‚ Estrutura do Projeto

```bash
zoom-sidekick-mvp/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ transcription.py                 # Processamento de Ã¡udio auxiliar
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                      # Entry point FastAPI
â”‚   â”‚   â”œâ”€â”€ routes.py                    # Endpoints da API
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ stt_service.py           # ğŸ™ï¸ Ãudio â†’ Texto (Whisper)
â”‚   â”‚   â”‚   â”œâ”€â”€ tts_service.py           # ğŸ”Š Texto â†’ Ãudio (gTTS)
â”‚   â”‚   â”‚   â”œâ”€â”€ summary_service.py       # ğŸ§  Resumo de respostas (GPT)
â”‚   â”‚   â”‚   â””â”€â”€ bot_service.py           # ğŸ¤– Orquestra o fluxo da entrevista
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ logger.py                # Logs estruturados
â”‚   â”‚       â””â”€â”€ config.py                # ConfiguraÃ§Ãµes globais da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ __init__.py                  # Inicializa o pacote de testes
â”‚   â”œâ”€â”€ requirements.txt                 # DependÃªncias do backend
â”‚   â””â”€â”€ Dockerfile                       # ConfiguraÃ§Ã£o do container backend
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html                        # Interface do usuÃ¡rio
â”‚   â”œâ”€â”€ recorder.js                       # Captura Ã¡udio
â”‚   â””â”€â”€ style.css                         # Estilo moderno e responsivo
â”œâ”€â”€ .env.example                          # VariÃ¡veis de ambiente de exemplo
â”œâ”€â”€ .gitignore                            # Arquivos ignorados
â”œâ”€â”€ docker-compose.yml                     # OrquestraÃ§Ã£o de containers
â””â”€â”€ README.md                              # DocumentaÃ§Ã£o
```

## âš™ï¸ Tecnologias Utilizadas

| ServiÃ§o     | Tecnologia              | FunÃ§Ã£o                                  |
| ----------- | ----------------------- | --------------------------------------- |
| STT ğŸ™ï¸      | Whisper (OpenAI)        | TranscriÃ§Ã£o de Ã¡udio                    |
| TTS ğŸ”Š      | gTTS                    | ConversÃ£o de texto em Ã¡udio             |
| Resumo ğŸ§    | OpenAI GPT              | Resumir respostas do candidato          |
| Backend ğŸ–¥ï¸  | Python 3.11 + FastAPI   | API rÃ¡pida e modular                    |
| Frontend ğŸŒ | HTML5, CSS3, JS         | Captura Ã¡udio e interaÃ§Ã£o com o usuÃ¡rio |
| Deploy ğŸ³   | Docker & Docker Compose | ContainerizaÃ§Ã£o                         |

## InstalaÃ§Ã£o de DependÃªncias

O projeto tem suporte a Windows e Linux/Mac.
Escolha o arquivo de requirements correspondente ao seu sistema:

Windows (CPU only)

InstalaÃ§Ã£o:

pip install -r requirements-windows.txt


Exemplo de requirements-windows.txt:

# Backend
fastapi==0.103.2
uvicorn[standard]==0.23.2
pydantic==2.5.1

# OpenAI / IA
openai==1.32.0
whisper==1.1.10
torch==2.3.1         # CPU / Windows

# TTS
gTTS==2.3.2

# ManipulaÃ§Ã£o de Ã¡udio
pydub==0.25.1
ffmpeg-python==0.2.0
soundfile==0.12.1

# UtilitÃ¡rios
python-dotenv==1.0.1
loguru==0.7.0
requests==2.31.0

Linux / WSL / Mac

InstalaÃ§Ã£o:

pip install -r requirements-linux.txt


Exemplo de requirements-linux.txt:

# Backend
fastapi==0.103.2
uvicorn[standard]==0.23.2
pydantic==2.5.1

# OpenAI / IA
openai==1.32.0
whisper==1.1.10
torch==2.3.1         # Linux/Mac (CPU por padrÃ£o)
# Para suporte CUDA/GPU, consulte a documentaÃ§Ã£o do PyTorch

# TTS
gTTS==2.3.2

# ManipulaÃ§Ã£o de Ã¡udio
pydub==0.25.1
ffmpeg-python==0.2.0
soundfile==0.12.1

# UtilitÃ¡rios
python-dotenv==1.0.1
loguru==0.7.0
requests==2.31.0


âš ï¸ ObservaÃ§Ã£o:

No Windows, a versÃ£o usada do torch Ã© apenas para CPU.

No Linux/Mac vocÃª pode instalar suporte a GPU caso tenha CUDA disponÃ­vel.


## ğŸ“ˆ Fluxo da Entrevista

```mermaid
flowchart TD
    A[UsuÃ¡rio inicia entrevista] --> B[Bot faz pergunta via TTS ğŸ”Š]

    B --> C[UsuÃ¡rio responde via microfone ğŸ™ï¸]

    C --> D[STT: Transcreve Ã¡udio para texto ğŸ“]

    D --> E[Summary: Resume resposta ğŸ§ ]

    E --> F[PrÃ³xima pergunta do bot ğŸ”Š]

    F --> B

    F --> G[Fim da entrevista]
```

ğŸ’¡ Fluxo contÃ­nuo atÃ© todas as perguntas serem feitas.
Cada resposta Ã© transcrita, resumida e o bot segue o prÃ³ximo passo automaticamente.


## ğŸƒâ€â™‚ï¸ Como Rodar o Projeto

### ğŸ“¥ Clone o repositÃ³rio

```bash
git clone https://github.com/magali-leodato/zoom-sidekick-mvp.git
cd zoom-sidekick-mvp
```

### ğŸ“„ VariÃ¡veis de Ambiente

Copie o arquivo `.env.example` para `.env` e configure:

```bash
OPENAI_API_KEY=your_openai_api_key
```

### ğŸ”§ Backend (FastAPI)

```bash
cd backend
python -m venv venv
source venv/bin/activate   # Linux / Mac
venv\Scripts\activate      # Windows

pip install -r requirements.txt
uvicorn app.main:app --reload
```

Backend disponÃ­vel em: ğŸ‘‰ `http://localhost:8000`

### ğŸ¨ Frontend

```bash
cd frontend
```

Abra `index.html` no navegador ou use a extensÃ£o **Live Server** no VSCode.

### ğŸ³ Docker (opcional)

```bash
docker-compose up --build
```

## ğŸ§ª Testes

Para rodar os testes unitÃ¡rios:

```bash
pytest backend/tests/
```


## ğŸ“¦ requirements.txt (backend)

Seu arquivo jÃ¡ estÃ¡ atualizado, mas certifique-se de conter pelo menos:

fastapi==0.99.0
uvicorn[standard]
openai
gtts
pytest
python-dotenv
```

Se estiver usando Whisper localmente, adicione:

```
whisper
```

E se estiver rodando em Docker, lembre-se de incluir tambÃ©m:

```
gunicorn
```

## ğŸ”œ PrÃ³ximos Passos

* ğŸ“¹ Captura de Ã¡udio diretamente do Zoom / Google Meet

* ğŸ¨ Melhorar UI/UX com feedback visual em tempo real

* ğŸ”’ Adicionar autenticaÃ§Ã£o e sessÃµes de usuÃ¡rio

* ğŸ—„ï¸ Persistir respostas em banco de dados

* âœ‰ï¸ FunÃ§Ãµes de follow-up (enviar e-mails, criar tarefas)


## ğŸ“¹ DemonstraÃ§Ã£o do MVP


[![â–¶ Assista ao vÃ­deo](https://img.youtube.com/vi/ymPnv9S1TAE/0.jpg)](https://youtu.be/ymPnv9S1TAE)



## ğŸ‘©â€ğŸ’» Desenvolvedor(a)

**Magali Leodato**

ğŸ”— [LinkedIn](http://www.linkedin.com/in/magali-santos-leodato)
ğŸ’» [GitHub](http://github.com/magali-leodato)


## ğŸ“œ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.
Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

